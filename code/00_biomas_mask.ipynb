{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento: Parte I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar os pacotes que serão usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: libopenjp2.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libopenjp2.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libwebp.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libwebp.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libmariadb.so.3: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libmariadb.so.3: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libjxl.so.0.8: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libjxl.so.0.8: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libOpenEXR-3_1.so.30: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libOpenEXR-3_1.so.30: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libhdf5.so.310: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libhdf5.so.310: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libnetcdf.so.19: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libnetcdf.so.19: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libheif.so.1: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libheif.so.1: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libcfitsio.so.10: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libcfitsio.so.10: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow_dataset.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow_dataset.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpoppler.so.126: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpoppler.so.126: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libopenjp2.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libopenjp2.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libwebp.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libwebp.so.7: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libmariadb.so.3: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libmariadb.so.3: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libjxl.so.0.8: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libjxl.so.0.8: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libOpenEXR-3_1.so.30: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libOpenEXR-3_1.so.30: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libhdf5.so.310: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libhdf5.so.310: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libnetcdf.so.19: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libnetcdf.so.19: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libheif.so.1: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libheif.so.1: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libcfitsio.so.10: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libcfitsio.so.10: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpq.so.5: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow_dataset.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow_dataset.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libarrow.so.1000: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpoppler.so.126: cannot open shared object file: No such file or directory\n",
      "ERROR 1: libpoppler.so.126: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from osgeo_utils.gdal_calc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checagem de arquivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer uma checagem dos arquivos que serão lidos, deve conter todos os biomas que foram rasterizados do Inventário Nacional no formato inventario_*bioma*_byte.tif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inventario_cerrado_byte.tif\n",
      "inventario_caatinga_byte.tif\n",
      "inventario_mata_atlantica_byte.tif\n",
      "inventario_pantanal_byte.tif\n",
      "inventario_pampa_byte.tif\n",
      "inventario_amazonia_byte.tif\n"
     ]
    }
   ],
   "source": [
    "# Especifica o caminho da pasta que contém os arquivos\n",
    "pasta = '../dados/inventario_v4_2016/inventario_biomas_rasters'\n",
    "\n",
    "# Obtém a lista de arquivos na pasta\n",
    "arquivos = os.listdir(pasta)\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    print(arquivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar as máscaras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo transfoma os mapas rasterizados do inventário em uma máscara binária, 1 onde o valor de pixel é maior que zero e 0 para o restante.\n",
    "Isso serve para criar o contorno do bioma que será replicado no MapBiomas, garantindo que os mapas terão a mesma quantidade de linha e colunas para serem comparáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo 1: processando o arquivo inventario_caatinga_byte.tif...\n",
      "\n",
      "Processo 0: processando o arquivo inventario_cerrado_byte.tif...\n",
      "\n",
      "Processo 1: o arquivo inventario_caatinga_byte.tif foi processado com sucesso!\n",
      "\n",
      "Processo 2: processando o arquivo inventario_mata_atlantica_byte.tif...\n",
      "\n",
      "Processo 0: o arquivo inventario_cerrado_byte.tif foi processado com sucesso!\n",
      "\n",
      "Processo 3: processando o arquivo inventario_pantanal_byte.tif...\n",
      "\n",
      "Processo 3: o arquivo inventario_pantanal_byte.tif foi processado com sucesso!\n",
      "\n",
      "Processo 4: processando o arquivo inventario_pampa_byte.tif...\n",
      "\n",
      "Processo 4: o arquivo inventario_pampa_byte.tif foi processado com sucesso!\n",
      "\n",
      "Processo 5: processando o arquivo inventario_amazonia_byte.tif...\n",
      "\n",
      "Processo 2: o arquivo inventario_mata_atlantica_byte.tif foi processado com sucesso!\n",
      "\n",
      "Processo 5: o arquivo inventario_amazonia_byte.tif foi processado com sucesso!\n",
      "\n",
      "Todos os arquivos foram processados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Supress the warning\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# Função que processa um arquivo\n",
    "def process_file(arquivo, pasta_inventario, pasta_biomas_mask, n_processo, status):\n",
    "    print(f\"Processo {n_processo}: processando o arquivo {arquivo}...\\n\")\n",
    "\n",
    "    Calc(\"((A > 0)/(A > 0))\", A=f\"{pasta_inventario}/{arquivo}\", \n",
    "         outfile=f\"{pasta_biomas_mask}/mask{arquivo.split('inventario')[1]}\",\n",
    "         type='Byte', overwrite=True, extent='intersect', quiet=True)\n",
    "    \n",
    "    print(f\"Processo {n_processo}: o arquivo {arquivo} foi processado com sucesso!\\n\")\n",
    "    status[arquivo] = False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Especifica o caminho da pasta que contém os arquivos\n",
    "    pasta_inventario = '../dados/inventario_v4_2016/inventario_biomas_rasters'\n",
    "    pasta_biomas_mask = '../dados/biomas_mask'\n",
    "\n",
    "    # Obtém a lista de arquivos na pasta\n",
    "    arquivos = os.listdir(pasta_inventario)\n",
    "\n",
    "    # Define o número máximo de processos em execução simultaneamente\n",
    "    max_processes = 2\n",
    "\n",
    "    # Inicializa o pool de processos e o objeto Manager para compartilhar dados entre processos\n",
    "    pool = Pool(processes=max_processes)\n",
    "    manager = Manager()\n",
    "\n",
    "    # Cria um dicionário compartilhado para armazenar o status de processamento de cada arquivo\n",
    "    status = manager.dict([(arquivo, False) for arquivo in arquivos])\n",
    "\n",
    "    # Loop pelos arquivos e executa o mesmo processo em cada um, usando o pool de processos\n",
    "    for i, arquivo in enumerate(arquivos):\n",
    "        # Aguarda até que haja um processo livre para executar o próximo arquivo\n",
    "        while True:\n",
    "            if sum(status.values()) < max_processes:\n",
    "                break\n",
    "\n",
    "        # Define o status do arquivo como \"em processamento\"\n",
    "        status[arquivo] = True\n",
    "\n",
    "        # Processa o arquivo em um novo processo\n",
    "        pool.apply_async(process_file, args=(arquivo, pasta_inventario, pasta_biomas_mask, i, status))\n",
    "\n",
    "    # Aguarda todos os processos terminarem\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Verifica se todos os processos foram finalizados\n",
    "    if sum(status.values()) == 0:\n",
    "        print(\"Todos os arquivos foram processados com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
